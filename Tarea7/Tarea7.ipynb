{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 7 del curso CM-072\n",
    "\n",
    "* Nombre y apellidos: Bitzer Arotoma Bacilio\n",
    "* Fecha de presentación: 17 de octubre.\n",
    "\n",
    "\n",
    "\n",
    "LendingClub es una compañía de préstamos *peer-to-peer* que conecta directamente a los prestatarios con potenciales prestamistas/inversionistas.\n",
    "\n",
    "Construirás un modelo de clasificación para predecir si un préstamo realizado a través del LendingClub tiene probabilidad de no ser pagado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loans = pd.read_csv(\"lending-club-data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 . Carga en una variable de nombre `todo_columnas` el nombre de todas las columnas del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
       "       'emp_length', 'home_ownership', 'annual_inc', 'is_inc_v', 'issue_d',\n",
       "       'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title',\n",
       "       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n",
       "       'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record',\n",
       "       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
       "       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
       "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
       "       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
       "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
       "       'policy_code', 'not_compliant', 'status', 'inactive_loans', 'bad_loans',\n",
       "       'emp_length_num', 'grade_num', 'sub_grade_num', 'delinq_2yrs_zero',\n",
       "       'pub_rec_zero', 'collections_12_mths_zero', 'short_emp',\n",
       "       'payment_inc_ratio', 'final_d', 'last_delinq_none', 'last_record_none',\n",
       "       'last_major_derog_none'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solucion\n",
    "todo_columnas = loans.columns\n",
    "todo_columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 . La columna que contiene la información que queremos predecir se llama `malos_prestamos`. En esta columna, el valor 1 significa un préstamo riesgoso (malo), mientras que 0 significa un préstamos seguro.\n",
    "\n",
    "Para hacer el trabajo más intuitivo, crea una nueva columna `prestamos_seguros` con el siguiente valor:\n",
    "\n",
    "* +1 si es un préstamo seguro\n",
    "* -1 si es un préstamos riesgoso (malo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucion\n",
    "loans['prestamos_seguros'] = loans.bad_loans.apply(lambda x : +1 if x==0 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 . Calcula la distribución en porcentaje de préstamos malos y préstamos buenos (debe sumar 100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bitzer/.local/lib/python3.5/site-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1    0.811185\n",
       "-1    0.188815\n",
       "Name: prestamos_seguros, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tu solución\n",
    "loans.prestamos_seguros.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 . Una manera de abordar conjuntos de datos desbalanceados es con un submuestreo  de la clase más grande hasta que la distribución de clases sea mitad y mitad. Vamos a realizar un submuestreo de los préstamos buenos para balancear nuestro conjunto de datos. Ello significa que vamos a descartar muchas observaciones. \n",
    "\n",
    "* Pon en una variable `prestamos_arriesgado` todos y solo los préstamos malos.\n",
    "* Pon en una variable `prestamos_seguros` una muestra aleatoria de préstamos buenos **del mismo tamaño** que la cantidad de préstamos malos. (Usa [pandas.DataFrame.sample](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html) con el atributo `random_state=0`)\n",
    "* Junta en una nueva variable `prestamos_balanceados`, los dos grupos anteriores: `prestamos_arriesgados` y `prestamos_seguros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>collections_12_mths_zero</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>final_d</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_record_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>prestamos_seguros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1071795</td>\n",
       "      <td>1306957</td>\n",
       "      <td>5600</td>\n",
       "      <td>5600</td>\n",
       "      <td>5600</td>\n",
       "      <td>60 months</td>\n",
       "      <td>21.28</td>\n",
       "      <td>152.39</td>\n",
       "      <td>F</td>\n",
       "      <td>F2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.57170</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1071570</td>\n",
       "      <td>1306721</td>\n",
       "      <td>5375</td>\n",
       "      <td>5375</td>\n",
       "      <td>5350</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>121.45</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.71600</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1064687</td>\n",
       "      <td>1298717</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>305.38</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.21520</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1069057</td>\n",
       "      <td>1303503</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>325.74</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.90888</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "1   1077430    1314167       2500         2500             2500   60 months   \n",
       "6   1071795    1306957       5600         5600             5600   60 months   \n",
       "7   1071570    1306721       5375         5375             5350   60 months   \n",
       "10  1064687    1298717       9000         9000             9000   36 months   \n",
       "12  1069057    1303503      10000        10000            10000   36 months   \n",
       "\n",
       "    int_rate  installment grade sub_grade        ...        delinq_2yrs_zero  \\\n",
       "1      15.27        59.83     C        C4        ...                     1.0   \n",
       "6      21.28       152.39     F        F2        ...                     1.0   \n",
       "7      12.69       121.45     B        B5        ...                     1.0   \n",
       "10     13.49       305.38     C        C1        ...                     1.0   \n",
       "12     10.65       325.74     B        B2        ...                     1.0   \n",
       "\n",
       "   pub_rec_zero collections_12_mths_zero  short_emp payment_inc_ratio  \\\n",
       "1           1.0                      1.0          1           2.39320   \n",
       "6           1.0                      1.0          0           4.57170   \n",
       "7           1.0                      1.0          1           9.71600   \n",
       "10          1.0                      1.0          1          12.21520   \n",
       "12          1.0                      1.0          0           3.90888   \n",
       "\n",
       "            final_d last_delinq_none last_record_none last_major_derog_none  \\\n",
       "1   20161201T000000                1                1                     1   \n",
       "6   20161201T000000                1                1                     1   \n",
       "7   20161201T000000                1                1                     1   \n",
       "10  20141201T000000                1                1                     1   \n",
       "12  20141201T000000                1                1                     1   \n",
       "\n",
       "   prestamos_seguros  \n",
       "1                 -1  \n",
       "6                 -1  \n",
       "7                 -1  \n",
       "10                -1  \n",
       "12                -1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tus soluciones\n",
    "prestamos_arrriesgado = loans[loans.prestamos_seguros==-1]\n",
    "prestamos_seguros = loans[loans.prestamos_seguros==1].sample(len(prestamos_arrriesgado),random_state=0)\n",
    "prestamos_balanceados = prestamos_arrriesgado.append(prestamos_seguros)\n",
    "prestamos_balanceados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 . Asigna a una variable `subconjunto_prestamos` sólo el siguiente subconjunto de características que son las que usaremos:\n",
    "\n",
    "```python\n",
    "caracteristica = ['grade',               # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "```\n",
    "\n",
    "Asimismo, asigna a una variable **`y`** los valores de la columna `prestamos_seguros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caracteristica = ['grade',               # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "subconjunto_prestamos = prestamos_balanceados.loc[:,caracteristica]\n",
    "y = prestamos_balanceados['prestamos_seguros']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46300, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subconjunto_prestamos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 .  Usando [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) convierte las variables categóricas de `subconjunto_prestamos` en variables numéricas *one-hot*. Guarda el nuevo conjunto de datos en `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46300, 67)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tu solucion\n",
    "X = pd.get_dummies(subconjunto_prestamos)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 .  Empleando `sklearn.model_selection.train_test_split` separa el conjunto de datos en un 90% para entrenamiento y validación (`X_entrenamiento_val`, `y_entrenamiento_val`), y 10% para pruebas (`X_prueba`, `y_prueba`).\n",
    "\n",
    "Luego separa (`X_entrenamiento_val`, `y_entrenamiento_val`) en un 80% para entrenamiento (`X_entrenamiento`, `y_entrenamiento`) y 20% para validación (`X_val`, `y_val`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_entrenamiento_val, X_prueba, y_entrenamiento_val, y_prueba = train_test_split( X, y, test_size=0.1) \n",
    "X_entrenamiento, X_val, y_entrenamiento, y_val = train_test_split( X_entrenamiento_val, y_entrenamiento_val, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 . Entrena un modelo como Regresión Logística, Naive Bayes, KNN y un cuarto modelo de tu elección, con las siguientes indicaciones:\n",
    "\n",
    "* Utilizar el uso apropiado de la normalización (Scaling) de datos si fuese necesario.\n",
    "* El uso apropiado de una técnica para la selección de los mejores parámetros de cada modelo (p.ej. búsqueda grid o búsqueda aleatoria)\n",
    "* Reporte para cada modelo la exactitud , precisión y exhaustividad, F1-Score  **en el conjunto de pruebas.** y muestra la matriz de confusión.\n",
    "* Comenta tus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tus soluciones\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<Regresion logistica>>>>>\n",
      "Training\n",
      "========\n",
      "Exactitud :  0.6461963042956563\n",
      "Precision :  0.6472191669456268\n",
      "F1-score :  0.6473894429695535\n",
      "Exhaustividad: 0.6475598086124402\n",
      "Matriz de confusion:\n",
      "[[13393  7377]\n",
      " [ 7366 13534]]\n",
      "\n",
      "Testing\n",
      "========\n",
      "Exactitud :  0.629805615550756\n",
      "Precision :  0.6154177433247201\n",
      "F1-score :  0.6251093613298339\n",
      "Exhaustividad: 0.6351111111111111\n",
      "Matriz de confusion:\n",
      "[[1487  893]\n",
      " [ 821 1429]]\n"
     ]
    }
   ],
   "source": [
    "logR = LogisticRegression()\n",
    "logR.fit(X_entrenamiento_val,y_entrenamiento_val)\n",
    "\n",
    "print(\"<<<<Regresion logistica>>>>>\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "y_predict = logR.predict(X_entrenamiento_val)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_entrenamiento_val,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_entrenamiento_val, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_entrenamiento_val,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n",
    "\n",
    "print(\"\\nTesting\")\n",
    "print(\"========\")\n",
    "y_predict = logR.predict(X_prueba)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_prueba,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_prueba,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_prueba,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_prueba, y_predict))\n",
    "\n",
    "m_c = metrics.confusion_matrix(y_prueba,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<Naive bayes>>>>>\n",
      "Training\n",
      "========\n",
      "Exactitud :  0.5876169906407488\n",
      "Precision :  0.554885974240813\n",
      "F1-score :  0.6861484511981297\n",
      "Exhaustividad: 0.898755980861244\n",
      "Matriz de confusion:\n",
      "[[ 5702 15068]\n",
      " [ 2116 18784]]\n",
      "\n",
      "Testing\n",
      "========\n",
      "Exactitud :  0.5730021598272138\n",
      "Precision :  0.5362165030512073\n",
      "F1-score :  0.6715401229440107\n",
      "Exhaustividad: 0.8982222222222223\n",
      "Matriz de confusion:\n",
      "[[ 632 1748]\n",
      " [ 229 2021]]\n"
     ]
    }
   ],
   "source": [
    "#segundo modelo\n",
    "gnb = MultinomialNB()\n",
    "gnb.fit(X_entrenamiento_val,y_entrenamiento_val);\n",
    "print(\"<<<<Naive bayes>>>>>\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "y_predict = gnb.predict(X_entrenamiento_val)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_entrenamiento_val,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_entrenamiento_val, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_entrenamiento_val,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n",
    "\n",
    "print(\"\\nTesting\")\n",
    "print(\"========\")\n",
    "y_predict = gnb.predict(X_prueba)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_prueba,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_prueba,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_prueba,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_prueba, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_prueba,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<KNN>>>>>\n",
      "Training\n",
      "========\n",
      "Exactitud :  0.7768178545716342\n",
      "Precision :  0.7698678578075563\n",
      "F1-score :  0.780618984714097\n",
      "Exhaustividad: 0.7916746411483253\n",
      "Matriz de confusion:\n",
      "[[15824  4946]\n",
      " [ 4354 16546]]\n",
      "Feactures analizados :  41670\n",
      "\n",
      "Testing\n",
      "========\n",
      "Exactitud :  0.5578833693304536\n",
      "Precision :  0.541010101010101\n",
      "F1-score :  0.5667724867724868\n",
      "Exhaustividad: 0.5951111111111111\n",
      "Matriz de confusion:\n",
      "[[1244 1136]\n",
      " [ 911 1339]]\n",
      "Feactures analizados :  4630\n",
      "\n",
      "Validación\n",
      "========\n",
      "Exactitud :  0.779097672186225\n",
      "Precision :  0.7721430240710446\n",
      "F1-score :  0.7821043910521956\n",
      "Exhaustividad: 0.7923261390887291\n",
      "Matriz de confusion:\n",
      "[[3189  975]\n",
      " [ 866 3304]]\n",
      "Feactures analizados :  8334\n"
     ]
    }
   ],
   "source": [
    "#tercer modelo\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_entrenamiento_val, y_entrenamiento_val)\n",
    "print(\"<<<<KNN>>>>>\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "y_predict = neigh.predict(X_entrenamiento_val)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_entrenamiento_val,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_entrenamiento_val, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_entrenamiento_val,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n",
    "print(\"Dimension : \",len(y_predict))\n",
    "\n",
    "print(\"\\nTesting\")\n",
    "print(\"========\")\n",
    "y_predict = neigh.predict(X_prueba)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_prueba,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_prueba,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_prueba,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_prueba, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_prueba,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n",
    "print(\" analizado : \",len(y_predict))\n",
    "\n",
    "print(\"\\nValidación\")\n",
    "print(\"========\")\n",
    "y_predict = neigh.predict(X_val)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_val,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_val,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_val,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_val, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_val,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n",
    "print(\"Datos analizados : \",len(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<Random Forest>>>>>\n",
      "Training\n",
      "========\n",
      "Exactitud :  0.6320614350851932\n",
      "Precision :  0.6220731386477243\n",
      "F1-score :  0.6492014826339633\n",
      "Exhaustividad: 0.6788038277511962\n",
      "Matriz de confusion:\n",
      "[[12151  8619]\n",
      " [ 6713 14187]]\n",
      "\n",
      "Testing\n",
      "========\n",
      "Exactitud :  0.616414686825054\n",
      "Precision :  0.5936758893280633\n",
      "F1-score :  0.6284518828451883\n",
      "Exhaustividad: 0.6675555555555556\n",
      "Matriz de confusion:\n",
      "[[1352 1028]\n",
      " [ 748 1502]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=4)\n",
    "clf.fit(X_entrenamiento_val, y_entrenamiento_val)\n",
    "print(\"<<<<Random Forest>>>>>\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "y_predict = clf.predict(X_entrenamiento_val)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_entrenamiento_val,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_entrenamiento_val,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_entrenamiento_val, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_entrenamiento_val,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)\n",
    "\n",
    "print(\"\\nTesting\")\n",
    "print(\"========\")\n",
    "y_predict = clf.predict(X_prueba)\n",
    "print(\"Exactitud : \",metrics.accuracy_score(y_prueba,y_predict))\n",
    "print(\"Precision : \",metrics.precision_score(y_prueba,y_predict))\n",
    "print(\"F1-score : \",metrics.f1_score(y_prueba,y_predict))\n",
    "print(\"Exhaustividad:\", metrics.recall_score(y_prueba, y_predict))\n",
    "m_c = metrics.confusion_matrix(y_prueba,y_predict)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(m_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios \n",
    "De los 4 modelos el que presenta la precisión mas baja es el Naive Bayes pero a sus vez es el que presenta mayor exhaustividad lo que significa que hay pocos falsos negativos a comparación de los otros modelos pero no significa que sea un buen modelo ya que comparando ambas metricas la precisión tiene mayor peso a comparación de la exhaustividad, por lo que no es un buen modelo. El mejor modelo que se aplico en este caso es el KNN pero este solo se da cuando tienes una gran cantidad de data para el testing, ya que como se observa con la data del testing se tiene unas bajas metricas a comparación de la data de validación que posee el doble de data para analizar y tiene mayor scoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
